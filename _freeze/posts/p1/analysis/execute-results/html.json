{
  "hash": "7660dbfbd3ec97fe638bfa49808b59d3",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Student Performance Predictor\"\nauthor: \"Shifa Panjwani\"\ndate: \"2025-03-20\"\ncategories: [tidymodels, tidyverse, ggplot2]\neditor: visual\nformat:\n  html:\n    embed-resources: true\ntitle-block-banner: true\n---\n\n\n\n## Problem Statement\n\nIn the field of education, understanding the factors influencing student performance is critical for improving academic outcomes. This project aims to develop a predictive model to estimate students' Math scores using the [**Student Performance Prediction**](https://www.kaggle.com/datasets/spscientist/students-performance-in-exams?datasetId=74977) dataset. The dataset contains various demographic and academic features, including **gender**, **race/ethnicity**, **parental education level**, **lunch type**, **test preparation course completion**, as well as **reading and writing scores**.\n\nThe primary objective is to analyze how these factors contribute to Math performance and create an accurate machine learning model that can predict Math scores.\n\n**Key Goals:**\n\n-   Develop a regression-based predictive model to estimate Math scores\n\n-   Perform EDA to identify patterns and correlations\n\n-   Evaluate linear and KNN model performances using appropriate metrics (e.g., RMSE, R-squared)\n\n-   Identify the best model\n\nThis project will leverage various machine learning algorithms and evaluate their effectiveness to select the best-performing model. The results will offer valuable insights into the factors influencing Math achievement and suggest strategies for academic support.\n\n## Data: Students Performance in Exams\n\nThere are 8 columns and 1000 rows. The primary variables of interest are:\n\n-   *`gender`:* Gender of the student\n\n-   *`race_ethnicity`*: Race/ethnicity of the student\n\n-   *`parental_level_of_education`*: Highest degree earned by student's parents\n\n-   *`lunch`:* Type of lunch plan the student is registered for\n\n-   *`test_preparation_course`*: Whether they took a test preparation course\n\n-   *`math_score`*: Student's math score\n\n-   *`reading_score`*: Student's reading score\n\n-   *`writing_score`*: Student's writing score\n\nThe ultimate goal will be to predict *`math_score`* using the other features.\n\n## Loading Libraries\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse)\nlibrary(tidymodels)\nlibrary(ggplot2)\nlibrary(ISLR2)\nlibrary(dplyr)\nlibrary(readr)\nlibrary(knitr)\n```\n:::\n\n\n\n## Loading Dataset\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndata <- read_csv('stud.csv')\nkable(head(data))\n```\n\n::: {.cell-output-display}\n\n\n|gender |race_ethnicity |parental_level_of_education |lunch        |test_preparation_course | math_score| reading_score| writing_score|\n|:------|:--------------|:---------------------------|:------------|:-----------------------|----------:|-------------:|-------------:|\n|female |group B        |bachelor's degree           |standard     |none                    |         72|            72|            74|\n|female |group C        |some college                |standard     |completed               |         69|            90|            88|\n|female |group B        |master's degree             |standard     |none                    |         90|            95|            93|\n|male   |group A        |associate's degree          |free/reduced |none                    |         47|            57|            44|\n|male   |group C        |some college                |standard     |none                    |         76|            78|            75|\n|female |group B        |associate's degree          |standard     |none                    |         71|            83|            78|\n\n\n:::\n:::\n\n\n\n## Exploratory Data Analysis\n\n### Missing Values\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsum(is.na(data))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0\n```\n\n\n:::\n:::\n\n\n\n### Near-Zero Variance & Lumping\n\nThis section checks the distribution of categorical variables in the dataset. The goal was to identify categories with near-zero variance (very few occurrences), however, none of the categories qualified for it. Hence, there's no need for lumping.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndata |> count(gender) |> kable()\n```\n\n::: {.cell-output-display}\n\n\n|gender |   n|\n|:------|---:|\n|female | 518|\n|male   | 482|\n\n\n:::\n\n```{.r .cell-code}\ndata |> count(race_ethnicity) |> kable()\n```\n\n::: {.cell-output-display}\n\n\n|race_ethnicity |   n|\n|:--------------|---:|\n|group A        |  89|\n|group B        | 190|\n|group C        | 319|\n|group D        | 262|\n|group E        | 140|\n\n\n:::\n\n```{.r .cell-code}\ndata |> count(parental_level_of_education) |> kable()\n```\n\n::: {.cell-output-display}\n\n\n|parental_level_of_education |   n|\n|:---------------------------|---:|\n|associate's degree          | 222|\n|bachelor's degree           | 118|\n|high school                 | 196|\n|master's degree             |  59|\n|some college                | 226|\n|some high school            | 179|\n\n\n:::\n\n```{.r .cell-code}\ndata |> count(lunch) |> kable()\n```\n\n::: {.cell-output-display}\n\n\n|lunch        |   n|\n|:------------|---:|\n|free/reduced | 355|\n|standard     | 645|\n\n\n:::\n\n```{.r .cell-code}\ndata |> count(test_preparation_course) |> kable()\n```\n\n::: {.cell-output-display}\n\n\n|test_preparation_course |   n|\n|:-----------------------|---:|\n|completed               | 358|\n|none                    | 642|\n\n\n:::\n:::\n\n\n\n### Math Score vs. Gender\n\n**Hypothesis**: Math scores would be quite similar for both genders.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(data, aes(x = gender, y = math_score, fill = gender)) +\n  geom_boxplot() +\n  labs(title = \"Gender vs Math Score\")\n```\n\n::: {.cell-output-display}\n![](analysis_files/figure-html/unnamed-chunk-5-1.png){width=672}\n:::\n:::\n\n\n\n-   Male students tend to score slightly better in math than female students.\n\n### Math Score vs. Test Preparation Course\n\n**Hypothesis**: Math scores would be higher for students who took the test preparation course.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(data, aes(x = test_preparation_course, y = math_score, fill = test_preparation_course)) +\n  geom_boxplot() +\n  labs(title = \"Test Preparation Course vs Math Score\")\n```\n\n::: {.cell-output-display}\n![](analysis_files/figure-html/unnamed-chunk-6-1.png){width=672}\n:::\n:::\n\n\n\n-   Students who had completed a test preparation course scored higher in math than those who had not taken it.\n\n### Correlation Matrix\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncorrelation_matrix <- cor(data |>\n                            select_if(is.numeric))\nprint(correlation_matrix)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n              math_score reading_score writing_score\nmath_score     1.0000000     0.8175797     0.8026420\nreading_score  0.8175797     1.0000000     0.9545981\nwriting_score  0.8026420     0.9545981     1.0000000\n```\n\n\n:::\n:::\n\n\n\n-   Reading and Writing scores have a high positive correlation.\n\n-   Math scores, with each of Reading and Writing scores also have moderate positive correlations.\n\n## Data Pre-processing\n\n### Categorical Columns to Factors\n\nThis code converts all categorical columns in the dataset from 'character' to 'factor' type, to ensure they are treated appropriately during modeling.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndata <- data |>\n  mutate(across(where(is.character), as.factor))\n```\n:::\n\n\n\n### Data Splitting\n\nWe split the data into train (70%) and test (30%) sets.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(427)\ndata_split <- initial_split(data, prop = 0.7)\ntrain_data <- training(data_split)\ntest_data <- testing(data_split)\n```\n:::\n\n\n\n-   There are 1000 rows in this dataset.\n\n-   After a 70/30 split, there are 700 rows in training set and 300 in test set.\n\n### Linear Regression Recipes\n\nThis section creates 3 different data pre-processing pipelines using the `recipes` package from `tidymodels` to prepare data for linear regression models. Each recipe applies various imputation, encoding and normalization techniques to handle missing values, categorical data, and scaling.\n\n#### Recipe 1: Mean Imputation + Dummy Encoding + Normalization\n\n-   **Mean Imputation:** Missing numeric values are replaced with the mean of the respective columns.\n\n-   **Unknown Category Assignment:** Unknown levels in categorical variables are handled.\n\n-   **Dummy Encoding:** Categorical variables are converted into dummy (binary) variables for linear regression.\n\n-   **Linear Combination Check:** Multi-collinear functions are detected and removed.\n\n-   **Normalization:** Numeric features are scaled to have a mean of zero and standard deviation of one.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nrecipe_lm1 <- recipe(math_score ~ ., data = train_data) |>\n  step_impute_mean(all_numeric_predictors()) |>\n  step_unknown(all_nominal_predictors()) |>\n  step_dummy(all_nominal_predictors()) |>\n  step_lincomb(all_predictors()) |>\n  step_normalize(all_numeric_predictors())\n```\n:::\n\n\n\n#### Recipe 2: Median Imputation + Zero-Variance Removal + Ordinal Encoding\n\n-   **Median Imputation:** Missing numeric values are replaced with median of each column.\n\n-   **Zero-Variance Removal:** Features with zero or near-zero variance are removed.\n\n-   **Ordinal Encoding:** Categorical variables are encoded as integers based on their levels.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nrecipe_lm2 <- recipe(math_score ~ ., data = train_data) |>\n  step_impute_median(all_numeric_predictors()) |>\n  step_unknown(all_nominal_predictors()) |>\n  step_zv(all_predictors()) |>\n  step_integer(all_nominal_predictors()) |>\n  step_lincomb(all_predictors()) |>\n  step_normalize(all_numeric_predictors())\n```\n:::\n\n\n\n#### Recipe 3: KNN Imputation + Lumping Rare Categories + Normalization\n\n-   **KNN Imputation:** Missing numeric values are imputed using the KNN method.\n\n-   **Lumping Rare Categories:** Categorical variables with a frequency below 5% are grouped into an 'Other' category.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nrecipe_lm3 <- recipe(math_score ~ ., data = train_data) |>\n  step_impute_knn(all_numeric_predictors()) |>\n  step_unknown(all_nominal_predictors()) |>\n  step_other(all_nominal_predictors(), threshold = 0.05) |>\n  step_dummy(all_nominal_predictors()) |>\n  step_lincomb(all_predictors()) |>\n  step_zv(all_predictors()) |>\n  step_normalize(all_numeric_predictors())\n```\n:::\n\n\n\n### KNN Recipes\n\nThis section creates 3 different data preprocessing pipelines using the 'recipes' package from tidymodels to prepare data for KNN regression models. Each recipe applies various imputation, encoding and normalization techniques to prepare data for effective model training.\n\n#### Recipe 1: Mean Imputation + One-Hot Encoding + Zero-Variance Removal +Normalization\n\n-   **One-Hot Encoding:** Categorical variables are converted into multiple binary columns using 'step_dummy' with one-hot encoding.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nrecipe_knn1 <- recipe(math_score ~ ., data = train_data) |>\n  step_impute_mean(all_numeric_predictors()) |>  \n  step_unknown(all_nominal_predictors()) |>  \n  step_dummy(all_nominal_predictors(), one_hot = TRUE) |>  \n  step_zv(all_predictors()) |> \n  step_normalize(all_numeric_predictors())\n```\n:::\n\n\n\n#### Recipe 2: Median Imputation + Lumping Rare Categories + Zero-Variance Removal + Normalization\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nrecipe_knn2 <- recipe(math_score ~ ., data = train_data) |>\n  step_impute_median(all_numeric_predictors()) |>  \n  step_other(all_nominal_predictors(), threshold = 0.02) |>  \n  step_dummy(all_nominal_predictors(), one_hot = TRUE) |>  \n  step_zv(all_predictors()) |> \n  step_normalize(all_numeric_predictors())\n```\n:::\n\n\n\n#### Recipe 3: KNN Imputation + Zero-Variance Removal + Normalization\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nrecipe_knn3 <- recipe(math_score ~ ., data = train_data) |>\n  step_impute_knn(all_numeric_predictors()) |>  \n  step_unknown(all_nominal_predictors()) |>  \n  step_dummy(all_nominal_predictors(), one_hot = TRUE) |>  \n  step_zv(all_predictors()) |>  \n  step_normalize(all_numeric_predictors())\n```\n:::\n\n\n\n## Model Definition\n\nThis section focuses on **Linear Regression** & **KNN Regression** and defines the two fundamentally different approaches:\n\n1.  **Linear Regression** provide simple, interpretable model. It serves as a baseline and helps identify direct relationships between predictors and math scores.\n2.  **KNN Regression** is a non-parametric, instance-based method that captures more complex, potentially non-linear patterns by predicting values based on neighboring data points.\n\nBy selecting these two models, we strike a balance between interpretability and flexibility, allowing us to evaluate how well each captures the underlying patterns in student performance.\n\n### Linear Regression\n\nThis model will be used to establish a linear relationship between the features and the math scores.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlm_model <- linear_reg() |>  \n  set_engine(\"lm\")\n```\n:::\n\n\n\n### KNN Models\n\n-   *`knn_model3`* uses 3 nearest neighbors for prediction, making it more sensitive to local patterns.\n\n-   *`knn_model5`* uses 5 nearest neighbors, providing a balanced approach between accuracy and stability.\n\n-   *`knn_model10`* uses 10 nearest neighbors, which may generalize better but could miss finer details.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nknn_model3 <- nearest_neighbor(neighbors = 3) |> \n  set_engine(\"kknn\") |> \n  set_mode(\"regression\")\nknn_model5 <- nearest_neighbor(neighbors = 5) |> \n  set_engine(\"kknn\") |> \n  set_mode(\"regression\")\nknn_model10 <- nearest_neighbor(neighbors = 10) |> \n  set_engine(\"kknn\") |> \n  set_mode(\"regression\")\n```\n:::\n\n\n\n## Workflow Creation\n\nThis section creates and organizes multiple workflows. Workflows are a convenient way to bundle together preprocessing recipes and models for streamlined model training and evaluation.\n\n### Linear Regression Workflow Set\n\nSince there's only one model, each recipe is paired with it, forming 3 distinct workflows.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlm_workflows <- workflow_set(\n  preproc = list(\n    \"lm_recipe1\" = recipe_lm1,\n    \"lm_recipe2\" = recipe_lm2,\n    \"lm_recipe3\" = recipe_lm3\n  ),\n  models = list(\n    \"lm_model\" = lm_model\n  ),\n  cross = TRUE\n)\n```\n:::\n\n\n\n### KNN Workflow Set\n\n-   The `cross = TRUE` parameter ensures that all recipes are applied to each of the models, creating a comprehensive set of workflows.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nknn_workflows <- workflow_set(\n  preproc = list(\n    \"knn_recipe1\" = recipe_knn1,\n    \"knn_recipe2\" = recipe_knn2,\n    \"knn_recipe3\" = recipe_knn3\n  ),\n  models = list(\n    \"knn_3\" = knn_model3,\n    \"knn_5\" = knn_model5,\n    \"knn_10\" = knn_model10\n  ),\n  cross = TRUE\n)\n```\n:::\n\n\n\n### Combining All Workflows\n\nGathers all possible combinations of preprocessing recipes and models, providing a consolidated set of workflows for model training, validation and comparison.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nall_workflows <- lm_workflows |> \n  bind_rows(knn_workflows)\n```\n:::\n\n\n\n## Cross-Validation & Model Evaluation\n\nThis section performs cross-validation to evaluate the performance of different models and preprocessing pipelines. It uses repeated k-fold cross-validation to ensure robust and reliable model reassessment.\n\n**Cross-Validation:** Split the training data into 5 folds and repeat the process 5 times. It minimizes model bias and variance by averaging results across different folds.\n\n**Evaluation Metrics:**\n\n-   Using **RMSE** (Root Mean Squared Error) to measure the average magnitude of prediction errors, with greater emphasis on larger errors, making it useful for understanding model accuracy in the same units as the target variable (Math score).\n\n-   **R-squared** complements this by indicating the proportion of variance in Math scores explained by the model\n\n**Workflow Mapping:** Applying all workflows to the cross-validation splits.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(427)\n\ncv_splits <- vfold_cv(train_data, v = 5, repeats = 5)\nmetrics <- metric_set(rmse, rsq)\n\ncv_results <- workflow_map(\n  all_workflows,\n  resamples = cv_splits,\n  metrics = metrics\n)\n\ncv_metrics <- cv_results |> collect_metrics()\n```\n:::\n\n\n\n## Visualization of Model Performance\n\n### RMSE Plot\n\nVisualizing Root Mean Squared Error values for each workflow, measuring the average error between predicted and actual Math scores. Lower RMSE indicates better model performance.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(cv_metrics |> filter(.metric == \"rmse\"), aes(x = wflow_id, y = mean, fill = model)) +\n  geom_col(position = \"dodge\") +\n  coord_flip() +\n  labs(\n    title = \"RMSE Comparison of Workflows\",\n    x = \"Workflow ID\",\n    y = \"Mean RMSE\"\n  ) +\n  theme_minimal()\n```\n\n::: {.cell-output-display}\n![](analysis_files/figure-html/unnamed-chunk-22-1.png){width=672}\n:::\n:::\n\n\n\n### R-Squared Plot\n\nVisualizing the Mean R-Squared values for each workflow, showing how well the model explains the variance in Math scores. Higher R-squared indicates better model performance.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(cv_metrics |> filter(.metric == \"rsq\"), aes(x = wflow_id, y = mean, fill = model)) +\n  geom_col(position = \"dodge\") +\n  coord_flip() +\n  labs(\n    title = \"R-Squared Comparison of Workflows\",\n    x = \"Workflow ID\",\n    y = \"Mean R-Squared\"\n  ) +\n  theme_minimal()\n```\n\n::: {.cell-output-display}\n![](analysis_files/figure-html/unnamed-chunk-23-1.png){width=672}\n:::\n:::\n\n\n\n**`lm_recipe1_lm_model`** is the our **best performing model** since it has the lowest RMSE and highest R-Squared.\n\n## Model Selection, Fitting & Evaluation\n\nThe final model selected is the **Linear Regression model trained using Recipe 1**, which includes mean imputation, dummy encoding, and normalization.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Extract and Fit Best Model\nbest_workflow <- all_workflows |>\n  extract_workflow(\"lm_recipe1_lm_model\") \n\n# Re-fit the model\nset.seed(427)\ndata_split <- initial_split(data, prop = 0.7)\nfinal_fit <- last_fit(best_workflow, split = data_split, metrics = metric_set(rmse, rsq))\n\n# Evaluate on Test Set\ntest_metrics <- collect_metrics(final_fit)\nkable(test_metrics)\n```\n\n::: {.cell-output-display}\n\n\n|.metric |.estimator | .estimate|.config              |\n|:-------|:----------|---------:|:--------------------|\n|rmse    |standard   |  5.327863|Preprocessor1_Model1 |\n|rsq     |standard   |  0.868077|Preprocessor1_Model1 |\n\n\n:::\n:::\n\n\n\n-   On the test data, it achieved an **RMSE of 5.33**, indicating that the model's predictions are, on average, within about 5.33 points of the actual Math scores.\n\n-   The **R-squared value of 0.868** shows that the model explains approximately 86.8% of the variance in Math scores, suggesting a strong fit.\n\n-   Overall, the model demonstrates **solid predictive performance** and **generalizes well to unseen data**.\n\nThis step concludes the modeling process, offering a clear measure of the model's predictive accuracy and effectiveness.\n",
    "supporting": [
      "analysis_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}